{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examples of Plotting FV3 Forecast Files\n",
    "\n",
    "FV3 forecasts are written out in two separate files at each output time. Files prefixed `dynf` contain 3D dynamics variables, while files prefixed `phyf` contain physics forecast information, mainly at the surface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This first cell is to run the common blocks before calling plotting, with input for the forecast hours - fhr. This way the whole notebook looks cleaner.\n",
    "\n",
    "Main functions are to import packages, read in and define data, define plotting functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import sys\n",
    "from argparse import Namespace\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.basemap import Basemap, shiftgrid\n",
    "import numpy as np\n",
    "from netCDF4 import Dataset\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from datetime import date, datetime, timedelta\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import fnmatch\n",
    "%matplotlib inline\n",
    "# plt.rcParams.update({'figure.max_open_warning': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initdate='2019043012'\n",
    "inithr=initdate[8:10]\n",
    "fhr=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provide a file path to a forecast directory. \n",
    "# The example below creates a dictionary containing 2 experiments, expt, through the first 4 forecast hours (including 0)\n",
    "exptlist=['k2n3.no_cu_gf', 'k6n2.no_cu_gf.L82_2mb']\n",
    "\n",
    "file_path='/scratch1/BMC/wrfruc/chunhua/fv3sar-testing/code/FV3SAR-DA/expt_dirs/expt_convection-tests/GSD_HRRR3km.GSD.dt30.{expt}/'+f'{initdate}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whether the two runs are using the same vertical coordinates, \n",
    "# this decides whether to plot fields at different levels where they have max values\n",
    "diff_vert_lev=True\n",
    "# diff_vert_lev=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = {expt: os.path.join(file_path.format(expt=expt)) for expt in exptlist }\n",
    "filecount1 = min(len(fnmatch.filter(os.listdir(folder[exptlist[0]]), 'phyf*.nc')),len(fnmatch.filter(os.listdir(folder[exptlist[0]]), 'dynf*.nc'))) \n",
    "filecount2 = min(len(fnmatch.filter(os.listdir(folder[exptlist[1]]), 'phyf*.nc')),len(fnmatch.filter(os.listdir(folder[exptlist[1]]), 'dynf*.nc')))\n",
    "last_fhr = min(filecount1, filecount2) - 1\n",
    "print('available forecast hours=', last_fhr)\n",
    "print('plotting forecast hour=', fhr)\n",
    "\n",
    "# check if fhr is out of range of the forecast files\n",
    "if (fhr > last_fhr):\n",
    "\tprint(\"forecast hour out of range, use the last fhr\")\n",
    "\tfhr = last_fhr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {expt: {x: [os.path.join(file_path.format(expt=expt), x + f'{i:03d}.nc') for i in range(last_fhr + 1)]  for x in ['dynf', 'phyf']} for expt in exptlist }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_lat, start_lon=(34,-98)\n",
    "end_lat, end_lon=(40, -88)\n",
    "numpoints=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_validdate(initdate, fhr):\n",
    "    # In this section: initdate + fhr = validdate\n",
    "    validdate=(datetime.strptime(initdate,\"%Y%m%d%H\")+timedelta(hours=fhr)).strftime(\"%Y%m%d%H\")\n",
    "    validday=validdate[0:8]\n",
    "    validhr=validdate[8:10]\n",
    "    return validdate, validday, validhr\n",
    "    \n",
    "validdate, validday, validhr=get_validdate(initdate, fhr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load each file in the files dict into a NetCDF Dataset\n",
    "\n",
    "def load_Dataset(files: dict, ds: dict):\n",
    "    assert(isinstance(files, dict))\n",
    "    for k, v in files.items():\n",
    "        if isinstance(v, dict):\n",
    "            ds[k] = {}\n",
    "            load_Dataset(v, ds[k])\n",
    "        else:\n",
    "            ds[k] = [Dataset(f, 'r') for f in list(v)]\n",
    "\n",
    "ds_dict = {}\n",
    "load_Dataset(files, ds_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dictionary into a Namespace data structure.\n",
    "# This step is not necessary, but cuts down the syntax needed to reference each item in the dict.\n",
    "#\n",
    "# Example: Retrieve the 0 hr forecast Dataset from GFS Dynamics\n",
    "#            dict: ds_dict['GFS']['dynf'][0]\n",
    "#       Namespace: datasets.GFS.dynf[0]\n",
    "\n",
    "\n",
    "def make_namespace(ns: Namespace(), d: dict):\n",
    "    assert(isinstance(d, dict))\n",
    "    for k, v in d.items():\n",
    "        if isinstance(v, dict):\n",
    "            leaf_ns = Namespace()\n",
    "            ns.__dict__[k] = leaf_ns\n",
    "            make_namespace(leaf_ns, v)\n",
    "        else:\n",
    "            ns.__dict__[k] = v\n",
    "   \n",
    "    \n",
    "datasets = Namespace()\n",
    "\n",
    "make_namespace(datasets, ds_dict)\n",
    " \n",
    "ds_dict[exptlist[0]]['dynf'][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('~~~~~~~~~ DYNAM FILE from GFS ~~~~~~~~~~~~~~~')\n",
    "# # for v, info in datasets.GFS.dynf[0].variables.items():\n",
    "# for v, info in ds_dict[exptlist[0]]['dynf'][0].variables.items():\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data_zoom(dataL, dataR, start_lat, start_lon, end_lat, end_lon, title, expt, zmax=None):\n",
    "    \n",
    "    '''\n",
    "    Input parameters:\n",
    "    \n",
    "        data: 2D Numpy array to be plotted in Left column\n",
    "        lat: 2D Numpy array of latitude\n",
    "        lon: 2D Numpy array of longitude\n",
    "        title: String describing the variable being plotted.\n",
    "        \n",
    "    Draws a Basemap representation with the contoured data overlayed, \n",
    "    with a colorbar for each experiment, and the difference between the two.\n",
    "        \n",
    "    '''\n",
    "\n",
    "    def trim_grid():\n",
    "        '''\n",
    "        The u, v, and H data from analysis are all on grids either one column, or one row smaller than lat/lon. \n",
    "        Return the smaller lat, lon grids, given the shape of the data to be plotted.\n",
    "        Has no effect when all grids are the same size.\n",
    "        '''\n",
    "        y, x = np.shape(dataL)\n",
    "        return lat[:y, :x], lon[:y, :x]\n",
    "    \n",
    "    def eq_contours(indata, indata2=None):\n",
    "        \n",
    "        '''\n",
    "        Returns a balanced set of contours for data that has negative values.\n",
    "        Also returns default colorbar to use for balanced, vs all positive values.\n",
    "        '''\n",
    "        cmap=plt.cm.get_cmap('bwr',20) \n",
    "        cmaplist = [cmap(i) for i in range(cmap.N)] \n",
    "        cmaplist[9] = [1,1,1,1] \n",
    "        cmaplist[10] = [1,1,1,1] \n",
    "        cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "       \n",
    "        minval = np.amin(indata) if indata2 is None else min(np.amin(indata), np.amin(indata2)) \n",
    "        maxval = np.amax(indata) if indata2 is None else max(np.amax(indata), np.amax(indata2))\n",
    "        \n",
    "        if minval == maxval:\n",
    "            return np.linspace(-1, 1, 11), 'seismic'\n",
    "        if np.amin(indata) < 0:\n",
    "        # Set balanced contours. Choose an odd number in linspace below\n",
    "            maxval = max(abs(minval), abs(maxval))\n",
    "            return np.linspace(-maxval, maxval, 21), cmap\n",
    "        else:\n",
    "            c = np.linspace(minval, maxval, 21)\n",
    "            if c[0] == 0:\n",
    "                c[0] = c[1]/10\n",
    "            return c, 'jet' \n",
    "   \n",
    "    lat_trim, lon_trim = trim_grid()\n",
    " \n",
    " #  add two more argumeents (fig, ax) to def plot_data(...)\n",
    "#     fig, ax = plt.subplots(figsize=(24, 12))\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    for i, data in enumerate([dataL, dataR]):    \n",
    "        m = Basemap(projection='mill', \n",
    "                    llcrnrlon=360+start_lon-5,\n",
    "                    urcrnrlon=360+end_lon+5 ,\n",
    "                    llcrnrlat=start_lat-5,\n",
    "                    urcrnrlat=end_lat+5,\n",
    "                    resolution='c',\n",
    "                    ax=ax[i],\n",
    "                   )\n",
    "        x, y = m(lon_trim, lat_trim)\n",
    "       \n",
    "        xlon=[360+start_lon, 360+end_lon] \n",
    "        xlat=[start_lat, end_lat]\n",
    "        xx, yy =m(xlon, xlat)\n",
    "     \n",
    "        # Use the same contour values for both experiments.\n",
    "        if i < 2:\n",
    "#         if i < 0:\n",
    "            contours, cm = eq_contours(dataL, dataR)\n",
    "        else:\n",
    "            contours, cm = eq_contours(data)\n",
    "                         \n",
    "        # Draw the contoured data over the map\n",
    "        cs = m.contourf(x, y, data, contours, cmap=cm, ax=ax[i])\n",
    "        m.plot(xx, yy, color='black', linewidth=3, linestyle='--', ax=ax[i]) \n",
    "        m.drawstates();\n",
    "        m.drawcoastlines();\n",
    "        m.drawmapboundary();\n",
    "        m.drawparallels(np.arange(-90.,120.,5),labels=[1,0,0,0]);\n",
    "        m.drawmeridians(np.arange(-180.,180.,10),labels=[0,0,0,1]);\n",
    "        fig.colorbar(cs, ax=ax[i], orientation='vertical', shrink=0.7);\n",
    "        if zmax is None:\n",
    "            ax[i].set_title(f\"{expt[i]}:\\n {title}\")\n",
    "        else:\n",
    "            ax[i].set_title(f\"{expt[i]}:\\n {title} at level {zmax[i]}\")\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latlon_to_xy(target_lat, target_lon):\n",
    "    y, x = np.unravel_index((np.abs(lat - target_lat) + np.abs(lon - target_lon-360)).argmin(), lat.shape)\n",
    "    return y,x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to derive values on the cross plane (3D to 2D) and make plots\n",
    "def plot_vertical_cross(dataL, dataR, start_lat, start_lon, end_lat, end_lon, numpoints, title, expt):\n",
    "    \n",
    "# get list of x,y points from start and end lat/lon\n",
    "    def get_xy_list(start_lat, start_lon, end_lat, end_lon, numpoints):\n",
    "        lat_dist=end_lat - start_lat\n",
    "        lon_dist=end_lon - start_lon\n",
    "        lat_list=np.zeros(numpoints)\n",
    "        lon_list=np.zeros(numpoints)\n",
    "        y_list=np.zeros(numpoints)\n",
    "        x_list=np.zeros(numpoints)\n",
    "        for i in range(numpoints):\n",
    "            lat_list[i]=start_lat + i * lat_dist / numpoints\n",
    "            lon_list[i]=start_lon + i * lon_dist / numpoints\n",
    "            y_list[i], x_list[i]=latlon_to_xy(lat_list[i], lon_list[i])\n",
    "        return y_list, x_list\n",
    "    \n",
    "    y_list, x_list=get_xy_list(start_lat, start_lon, end_lat, end_lon, numpoints)\n",
    "\n",
    "    def eq_contours(indata, indata2=None):\n",
    "        \n",
    "        '''\n",
    "        Returns a balanced set of contours for data that has negative values.\n",
    "        Also returns default colorbar to use for balanced, vs all positive values.\n",
    "        '''\n",
    "        cmap=plt.cm.get_cmap('bwr',20) \n",
    "        cmaplist = [cmap(i) for i in range(cmap.N)] \n",
    "        cmaplist[9] = [1,1,1,1] \n",
    "        cmaplist[10] = [1,1,1,1] \n",
    "        cmap = mpl.colors.LinearSegmentedColormap.from_list('Custom cmap', cmaplist, cmap.N)\n",
    "       \n",
    "        minval = np.amin(indata) if indata2 is None  else min(np.amin(indata), np.amin(indata2)) \n",
    "        maxval = np.amax(indata) if indata2 is None  else max(np.amax(indata), np.amax(indata2))\n",
    "        \n",
    "        if minval == maxval:\n",
    "            return np.linspace(-1, 1, 11), 'seismic'\n",
    "        if np.amin(indata) < 0:\n",
    "        # Set balanced contours. Choose an odd number in linspace below\n",
    "            maxval = max(abs(minval), abs(maxval))\n",
    "            return np.linspace(-maxval, maxval, 21), cmap\n",
    "        else:\n",
    "            c = np.linspace(minval, maxval, 21)\n",
    "            if c[0] == 0:\n",
    "                c[0] = c[1]/10\n",
    "            return c, 'jet' \n",
    "\n",
    "    # derive data on the cross section points\n",
    "    def var3dto2d(data, y_list, x_list, numpoints):\n",
    "        nlev=np.shape(data)[0]\n",
    "        data2d=np.zeros((nlev,numpoints))\n",
    "        for i in range(0, numpoints-1):\n",
    "            iy=int(y_list[i])\n",
    "            ix=int(x_list[i])\n",
    "            data2d[:, i]=data[:, iy, ix]\n",
    "        return data2d\n",
    "        \n",
    "    data2dL=var3dto2d(dataL, y_list, x_list, numpoints)\n",
    "    data2dR=var3dto2d(dataR, y_list, x_list, numpoints)\n",
    "\n",
    "# making vertical cross section plots \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    for i, data in enumerate([data2dL, data2dR]):\n",
    "\n",
    "        x=np.shape(data)[1]\n",
    "        y=np.shape(data)[0]\n",
    "\n",
    "        if i < 2:\n",
    "#         if i < 0:\n",
    "             contours, cm = eq_contours(data2dL, data2dR)\n",
    "        else:\n",
    "             contours, cm = eq_contours(data)\n",
    "                              \n",
    "        cs=ax[i].contourf(range(x),range(y)[::-1], data, contours, cmap=cm)\n",
    "        ax[i].set_title(f\"{expt[i]}: Cross Section \\n {title}\")\n",
    "        plt.colorbar(cs, ax=ax[i], orientation='vertical', shrink=0.9)\n",
    "        ax[i].grid()\n",
    "        \n",
    "    for ax in ax.flat:\n",
    "        ax.set(xlabel='Grid Points', ylabel='Vertical Levels')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(fhr)\n",
    "\n",
    "lat = ds_dict[exptlist[0]]['dynf'][fhr]['grid_yt'][::] * 180 / math.pi\n",
    "lon = ds_dict[exptlist[0]]['dynf'][fhr]['grid_xt'][::] * 180 / math.pi\n",
    "\n",
    "print(np.shape(lat))\n",
    "print(np.shape(lon))\n",
    "\n",
    "# Variables to plot from dynf and phyf files\n",
    "vars_ = {\n",
    "#     'dynf': ['ugrd', 'vgrd', 'dzdt', 'tmp', 'spfh', 'dpres','delz'],\n",
    "    'dynf': ['ugrd', 'vgrd', 'dzdt', 'tmp', 'spfh', 'dpres','delz'],\n",
    "#     'phyf': ['ugrd10m', 'vgrd10m', 'f10m', 'tmpsfc', 'tmp2m', 'spfh2m', 'pwatclm', 'tprcp', 'prate_ave', 'soilm', 'soilt1', 'pressfc', 'albdo_ave',  'lhtfl_ave', 'shtfl_ave', 'hpbl' ],\n",
    "\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### find the level where variable field has max values\n",
    "def find_lev_max(var3d):\n",
    "    nlev=np.shape(var3d)[0]\n",
    "    varmax=max(np.amax(var3d[i,:,:]) for i  in range(nlev))\n",
    "#     print(varmax)\n",
    "    for i in range(nlev):\n",
    "        if np.amax(var3d[i,:,:])==varmax :\n",
    "            zmax=i\n",
    "#     print(zmax)\n",
    "    return zmax\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "file = 'dynf'\n",
    "for var in vars_[file]:\n",
    "    dataL = np.squeeze(ds_dict[exptlist[0]][file][fhr][var][::])\n",
    "    dataR = np.squeeze(ds_dict[exptlist[1]][file][fhr][var][::])  \n",
    "    if var == 'spfh':\n",
    "        dataL = dataL * 1000.\n",
    "        dataR = dataR * 1000.\n",
    "    title = f'{var}: {fhr} hr fcst from {initdate} '\n",
    "    plot_vertical_cross(dataL, dataR, start_lat, start_lon, end_lat, end_lon, numpoints, title, exptlist)\n",
    "    \n",
    "    # for 2 model runs with same verticall levels, use zmax from one of the two\n",
    "    if diff_vert_lev:\n",
    "        zmaxL=find_lev_max(dataL)\n",
    "        zmaxR=find_lev_max(dataR)\n",
    "        zmax=[zmaxL, zmaxR]\n",
    "        data2dL=dataL[zmaxL,:,:]\n",
    "        data2dR=dataR[zmaxR,:,:]\n",
    "        title = f'{var}: {fhr} hr fcst from {initdate} '\n",
    "        plot_data_zoom(data2dL, data2dR, start_lat, start_lon, end_lat, end_lon, title, exptlist, zmax)\n",
    "    else: \n",
    "        zmax=find_lev_max(dataL)\n",
    "        data2dL=dataL[zmax,:,:]\n",
    "        data2dR=dataR[zmax,:,:]\n",
    "        title = f'{var}: {fhr} hr fcst from {initdate} at lev {zmax}'\n",
    "        plot_data_zoom(data2dL, data2dR, start_lat, start_lon, end_lat, end_lon, title, exptlist)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y1,x1=latlon_to_xy(start_lat, start_lon)\n",
    "# y2,x2=latlon_to_xy(end_lat, end_lon)\n",
    "# print(y1,x1)  \n",
    "# print(y2,x2)\n",
    "# print(lat[y1,x1], lon[y1,x1])\n",
    "# print(lat[y2,x2], lon[y2,x2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
